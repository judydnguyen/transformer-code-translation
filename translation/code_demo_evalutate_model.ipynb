{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "source=\"java\"\n",
    "target=\"cs\"\n",
    "lr=1e-4\n",
    "batch_size=64\n",
    "beam_size=10\n",
    "source_length=320\n",
    "target_length=256\n",
    "output_dir=f\"saved_models/{source}-{target}/\"\n",
    "train_file=f\"data/train.java-cs.txt.{source},data/train.java-cs.txt.{target}\"\n",
    "dev_file=f\"data/valid.java-cs.txt.{source},data/valid.java-cs.txt.{target}\"\n",
    "epochs=2\n",
    "pretrained_model=\"microsoft/graphcodebert-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import argparse\n",
    "import numpy as np\n",
    "from io import open\n",
    "from itertools import cycle\n",
    "import torch.nn as nn\n",
    "from model import Seq2Seq\n",
    "from tqdm import tqdm, trange\n",
    "from bleu import _bleu\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler,TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from transformers import (WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup,\n",
    "                          RobertaConfig, RobertaModel, RobertaTokenizer)\n",
    "MODEL_CLASSES = {'roberta': (RobertaConfig, RobertaModel, RobertaTokenizer)}\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "from parser import DFG_python,DFG_java,DFG_ruby,DFG_go,DFG_php,DFG_javascript,DFG_csharp\n",
    "from parser import (remove_comments_and_docstrings,\n",
    "                   tree_to_token_index,\n",
    "                   index_to_code_token,\n",
    "                   tree_to_variable_index)\n",
    "from tree_sitter import Language, Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg_function={\n",
    "    'python': DFG_python,\n",
    "    'java': DFG_java,\n",
    "    'ruby': DFG_ruby,\n",
    "    'go': DFG_go,\n",
    "    'php': DFG_php,\n",
    "    'javascript':DFG_javascript,\n",
    "    'c_sharp':DFG_csharp,\n",
    "}\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "#load parsers\n",
    "parsers={}        \n",
    "for lang in dfg_function:\n",
    "    # print(Language)\n",
    "    LANGUAGE = Language('parser/my-languages.so', lang)\n",
    "    parser = Parser()\n",
    "    parser.set_language(LANGUAGE) \n",
    "    parser = [parser,dfg_function[lang]]    \n",
    "    parsers[lang]= parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Example(object):\n",
    "    \"\"\"A single training/test example.\"\"\"\n",
    "    def __init__(self,\n",
    "                 source,\n",
    "                 target,\n",
    "                 lang\n",
    "                 ):\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "        self.lang=lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dataflow(code, parser,lang):\n",
    "    #remove comments\n",
    "    try:\n",
    "        code=remove_comments_and_docstrings(code,lang)\n",
    "    except:\n",
    "        pass    \n",
    "    #obtain dataflow\n",
    "    if lang==\"php\":\n",
    "        code=\"<?php\"+code+\"?>\"    \n",
    "    try:\n",
    "        tree = parser[0].parse(bytes(code,'utf8'))    \n",
    "        root_node = tree.root_node  \n",
    "        tokens_index=tree_to_token_index(root_node)     \n",
    "        code=code.split('\\n')\n",
    "        code_tokens=[index_to_code_token(x,code) for x in tokens_index]  \n",
    "        index_to_code={}\n",
    "        for idx,(index,code) in enumerate(zip(tokens_index,code_tokens)):\n",
    "            index_to_code[index]=(idx,code)  \n",
    "        try:\n",
    "            DFG,_=parser[1](root_node,index_to_code,{}) \n",
    "        except:\n",
    "            DFG=[]\n",
    "        DFG=sorted(DFG,key=lambda x:x[1])\n",
    "        indexs=set()\n",
    "        for d in DFG:\n",
    "            if len(d[-1])!=0:\n",
    "                indexs.add(d[1])\n",
    "            for x in d[-1]:\n",
    "                indexs.add(x)\n",
    "        new_DFG=[]\n",
    "        for d in DFG:\n",
    "            if d[1] in indexs:\n",
    "                new_DFG.append(d)\n",
    "        dfg=new_DFG\n",
    "    except:\n",
    "        dfg=[]\n",
    "    return code_tokens,dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_examples(filename):\n",
    "    \"\"\"Read examples from filename.\"\"\"\n",
    "    examples=[]\n",
    "    source,target=filename.split(',')\n",
    "    lang='java'\n",
    "    if source[-1]=='s':\n",
    "        lang='c_sharp'\n",
    "        \n",
    "    with open(source,encoding=\"utf-8\") as f1,open(target,encoding=\"utf-8\") as f2:\n",
    "        for line1,line2 in zip(f1,f2):\n",
    "            line1=line1.strip()\n",
    "            line2=line2.strip()\n",
    "            examples.append(\n",
    "                Example(\n",
    "                    source=line1,\n",
    "                    target=line2,\n",
    "                    lang=lang\n",
    "                        ) \n",
    "            )\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the input for BERT model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"A single training/test features for a example.\"\"\"\n",
    "    def __init__(self,\n",
    "                 example_id,\n",
    "                 source_ids,\n",
    "                 position_idx,\n",
    "                 dfg_to_code,\n",
    "                 dfg_to_dfg,                 \n",
    "                 target_ids,\n",
    "                 source_mask,\n",
    "                 target_mask,\n",
    "\n",
    "    ):\n",
    "        self.example_id = example_id\n",
    "        self.source_ids = source_ids\n",
    "        self.position_idx = position_idx\n",
    "        self.dfg_to_code = dfg_to_code\n",
    "        self.dfg_to_dfg = dfg_to_dfg\n",
    "        self.target_ids = target_ids\n",
    "        self.source_mask = source_mask\n",
    "        self.target_mask = target_mask       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, tokenizer, args,stage=None):\n",
    "    features = []\n",
    "    for example_index, example in enumerate(tqdm(examples,total=len(examples))):\n",
    "        ##extract data flow\n",
    "        code_tokens,dfg=extract_dataflow(example.source,\n",
    "                                         parsers[\"c_sharp\" if args.source_lang == \"cs\" else \"java\"],\n",
    "                                         \"c_sharp\" if args.source_lang == \"cs\" else \"java\")\n",
    "        code_tokens=[tokenizer.tokenize('@ '+x)[1:] if idx!=0 else tokenizer.tokenize(x) for idx,x in enumerate(code_tokens)]\n",
    "        ori2cur_pos={}\n",
    "        ori2cur_pos[-1]=(0,0)\n",
    "        for i in range(len(code_tokens)):\n",
    "            ori2cur_pos[i]=(ori2cur_pos[i-1][1],ori2cur_pos[i-1][1]+len(code_tokens[i]))    \n",
    "        code_tokens=[y for x in code_tokens for y in x]  \n",
    "        \n",
    "        #truncating\n",
    "        code_tokens=code_tokens[:args.max_source_length-3][:512-3]\n",
    "        source_tokens =[tokenizer.cls_token]+code_tokens+[tokenizer.sep_token]\n",
    "        source_ids =  tokenizer.convert_tokens_to_ids(source_tokens)\n",
    "        position_idx = [i+tokenizer.pad_token_id + 1 for i in range(len(source_tokens))]\n",
    "        dfg=dfg[:args.max_source_length-len(source_tokens)]\n",
    "        source_tokens+=[x[0] for x in dfg]\n",
    "        position_idx+=[0 for x in dfg]\n",
    "        source_ids+=[tokenizer.unk_token_id for x in dfg]\n",
    "        padding_length=args.max_source_length-len(source_ids)\n",
    "        position_idx+=[tokenizer.pad_token_id]*padding_length\n",
    "        source_ids+=[tokenizer.pad_token_id]*padding_length      \n",
    "        source_mask = [1] * (len(source_tokens))\n",
    "        source_mask+=[0]*padding_length        \n",
    "        \n",
    "        #reindex\n",
    "        reverse_index={}\n",
    "        for idx,x in enumerate(dfg):\n",
    "            reverse_index[x[1]]=idx\n",
    "        for idx,x in enumerate(dfg):\n",
    "            dfg[idx]=x[:-1]+([reverse_index[i] for i in x[-1] if i in reverse_index],)    \n",
    "        dfg_to_dfg=[x[-1] for x in dfg]\n",
    "        dfg_to_code=[ori2cur_pos[x[1]] for x in dfg]\n",
    "        length=len([tokenizer.cls_token])\n",
    "        dfg_to_code=[(x[0]+length,x[1]+length) for x in dfg_to_code]        \n",
    "      \n",
    "\n",
    "        #target\n",
    "        if stage==\"test\":\n",
    "            target_tokens = tokenizer.tokenize(\"None\")\n",
    "        else:\n",
    "            target_tokens = tokenizer.tokenize(example.target)[:args.max_target_length-2]\n",
    "        target_tokens = [tokenizer.cls_token]+target_tokens+[tokenizer.sep_token]            \n",
    "        target_ids = tokenizer.convert_tokens_to_ids(target_tokens)\n",
    "        target_mask = [1] *len(target_ids)\n",
    "        padding_length = args.max_target_length - len(target_ids)\n",
    "        target_ids+=[tokenizer.pad_token_id]*padding_length\n",
    "        target_mask+=[0]*padding_length   \n",
    "   \n",
    "        if example_index < 5:\n",
    "            if stage=='train':\n",
    "                logger.info(\"*** Example ***\")\n",
    "                logger.info(\"source_tokens: {}\".format([x.replace('\\u0120','_') for x in source_tokens]))\n",
    "                logger.info(\"source_ids: {}\".format(' '.join(map(str, source_ids))))\n",
    "                logger.info(\"source_mask: {}\".format(' '.join(map(str, source_mask))))\n",
    "                logger.info(\"position_idx: {}\".format(position_idx))\n",
    "                logger.info(\"dfg_to_code: {}\".format(' '.join(map(str, dfg_to_code))))\n",
    "                logger.info(\"dfg_to_dfg: {}\".format(' '.join(map(str, dfg_to_dfg))))\n",
    "                \n",
    "                logger.info(\"target_tokens: {}\".format([x.replace('\\u0120','_') for x in target_tokens]))\n",
    "                logger.info(\"target_ids: {}\".format(' '.join(map(str, target_ids))))\n",
    "                logger.info(\"target_mask: {}\".format(' '.join(map(str, target_mask))))\n",
    "       \n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                 example_index,\n",
    "                 source_ids,\n",
    "                 position_idx,\n",
    "                 dfg_to_code,\n",
    "                 dfg_to_dfg,\n",
    "                 target_ids,\n",
    "                 source_mask,\n",
    "                 target_mask,\n",
    "            )\n",
    "        )\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare fine-tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments: <__main__.Args object at 0x7fe7e7151480>\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "# Simulate argparse for Jupyter\n",
    "class Args:\n",
    "    model_type = \"roberta\"\n",
    "    model_name_or_path = \"roberta-base\"\n",
    "    output_dir = \"./output\"\n",
    "    load_model_path = None\n",
    "    train_filename = None\n",
    "    dev_filename = None\n",
    "    test_filename = None\n",
    "    source_lang = \"en\"\n",
    "    config_name = \"\"\n",
    "    tokenizer_name = \"\"\n",
    "    max_source_length = 64\n",
    "    max_target_length = 32\n",
    "    do_train = True\n",
    "    do_eval = True\n",
    "    do_test = False\n",
    "    do_lower_case = False\n",
    "    no_cuda = False\n",
    "    train_batch_size = 256\n",
    "    eval_batch_size = 512\n",
    "    gradient_accumulation_steps = 1\n",
    "    learning_rate = 5e-5\n",
    "    beam_size = 10\n",
    "    weight_decay = 0.0\n",
    "    adam_epsilon = 1e-8\n",
    "    max_grad_norm = 1.0\n",
    "    num_train_epochs = 3\n",
    "    max_steps = -1\n",
    "    eval_steps = -1\n",
    "    train_steps = -1\n",
    "    warmup_steps = 0\n",
    "    local_rank = -1\n",
    "    seed = 42\n",
    "\n",
    "# Create an instance of Args\n",
    "args = Args()\n",
    "\n",
    "# Print the arguments for verification\n",
    "print(f\"Arguments: {args}\")\n",
    "args.model_type = \"roberta\"\n",
    "args.source_lang = source\n",
    "args.target_lang = target\n",
    "args.model_name_or_path = pretrained_model\n",
    "args.tokenizer_name = \"microsoft/graphcodebert-base\"\n",
    "args.config_name = \"microsoft/graphcodebert-base\"\n",
    "args.train_filename = train_file\n",
    "args.dev_filename = dev_file\n",
    "args.output_dir = output_dir\n",
    "args.learning_rate = lr\n",
    "args.num_train_epochs = epochs\n",
    "args.train_batch_size = batch_size\n",
    "args.eval_batch_size = batch_size\n",
    "args.max_source_length = source_length\n",
    "args.max_target_length = target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare parsers for each language\n",
    "parsers={}        \n",
    "for lang in dfg_function:\n",
    "    LANGUAGE = Language('parser/my-languages.so', lang)\n",
    "    parser = Parser()\n",
    "    parser.set_language(LANGUAGE) \n",
    "    parser = [parser,dfg_function[lang]]    \n",
    "    parsers[lang]= parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYHTONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "set_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, examples, args):\n",
    "        self.examples = examples\n",
    "        self.args=args  \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        #calculate graph-guided masked function\n",
    "        attn_mask=np.zeros((self.args.max_source_length,self.args.max_source_length),dtype=np.bool_)\n",
    "        #calculate begin index of node and max length of input\n",
    "        node_index=sum([i>1 for i in self.examples[item].position_idx])\n",
    "        max_length=sum([i!=1 for i in self.examples[item].position_idx])\n",
    "        #sequence can attend to sequence\n",
    "        attn_mask[:node_index,:node_index]=True\n",
    "        #special tokens attend to all tokens\n",
    "        for idx,i in enumerate(self.examples[item].source_ids):\n",
    "            if i in [0,2]:\n",
    "                attn_mask[idx,:max_length]=True\n",
    "        #nodes attend to code tokens that are identified from\n",
    "        for idx,(a,b) in enumerate(self.examples[item].dfg_to_code):\n",
    "            if a<node_index and b<node_index:\n",
    "                attn_mask[idx+node_index,a:b]=True\n",
    "                attn_mask[a:b,idx+node_index]=True\n",
    "        #nodes attend to adjacent nodes         \n",
    "        for idx,nodes in enumerate(self.examples[item].dfg_to_dfg):\n",
    "            for a in nodes:\n",
    "                if a+node_index<len(self.examples[item].position_idx):\n",
    "                    attn_mask[idx+node_index,a+node_index]=True  \n",
    "                    \n",
    "        return (torch.tensor(self.examples[item].source_ids),\n",
    "                torch.tensor(self.examples[item].source_mask),\n",
    "                torch.tensor(self.examples[item].position_idx),\n",
    "                torch.tensor(attn_mask), \n",
    "                torch.tensor(self.examples[item].target_ids),\n",
    "                torch.tensor(self.examples[item].target_mask),)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup CUDA, GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "args.n_gpu = torch.cuda.device_count()\n",
    "args.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dir if output_dir not exist\n",
    "if os.path.exists(args.output_dir) is False:\n",
    "    os.makedirs(args.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training helpers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n",
    "config = config_class.from_pretrained(args.config_name)\n",
    "tokenizer = tokenizer_class.from_pretrained(args.tokenizer_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, output_dir, step):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model \n",
    "    output_model_file = os.path.join(output_dir, \"model.{}.bin\".format(step))\n",
    "    torch.save(model_to_save.state_dict(), output_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(model, eval_examples, eval_dataloader):\n",
    "    \n",
    "    model.eval() \n",
    "    p=[]\n",
    "    for batch in eval_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        source_ids,source_mask,position_idx,att_mask,target_ids,target_mask = batch                 \n",
    "        with torch.no_grad():\n",
    "            preds = model(source_ids, source_mask, position_idx, att_mask, target_ids, target_mask) \n",
    "            for pred in preds:\n",
    "                t=pred[0].cpu().numpy()\n",
    "                t=list(t)\n",
    "                if 0 in t:\n",
    "                    t=t[:t.index(0)]\n",
    "                text = tokenizer.decode(t,clean_up_tokenization_spaces=False)\n",
    "                p.append(text)\n",
    "    model.train()\n",
    "    predictions=[]\n",
    "    accs = []\n",
    "    with open(os.path.join(args.output_dir,\"dev.output\"),'w') as f, open(os.path.join(args.output_dir,\"dev.gold\"),'w') as f1:\n",
    "        for ref,gold in zip(p, eval_examples):\n",
    "            predictions.append(ref)\n",
    "            f.write(ref+'\\n')\n",
    "            f1.write(gold.target+'\\n')     \n",
    "            accs.append(ref==gold.target)\n",
    "\n",
    "    dev_bleu=round(_bleu(os.path.join(args.output_dir, \"dev.gold\"), os.path.join(args.output_dir, \"dev.output\")),2)\n",
    "    xmatch=round(np.mean(accs)*100,4)\n",
    "    \n",
    "    return dev_bleu,xmatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating with Pretrained Model Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:01<00:00, 402.65it/s]\n",
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 54 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "12/04/2024 19:39:44 - INFO - __main__ -   \n",
      "***** Running evaluation *****\n",
      "12/04/2024 19:39:44 - INFO - __main__ -     Num examples = 500\n",
      "12/04/2024 19:39:44 - INFO - __main__ -     Batch size = 64\n"
     ]
    }
   ],
   "source": [
    "# validation loader\n",
    "dev_dataset={}\n",
    "if 'dev_loss' in dev_dataset:\n",
    "    eval_examples,eval_data=dev_dataset['dev_loss']\n",
    "else:\n",
    "    eval_examples = read_examples(args.dev_filename)\n",
    "    eval_features = convert_examples_to_features(eval_examples, tokenizer, args,stage='dev')\n",
    "    eval_data = TextDataset(eval_features,args)\n",
    "    dev_dataset['dev_loss']=eval_examples,eval_data\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args.eval_batch_size,num_workers=54)\n",
    "\n",
    "logger.info(\"\\n***** Running evaluation *****\")\n",
    "logger.info(\"  Num examples = %d\", len(eval_examples))\n",
    "logger.info(\"  Batch size = %d\", args.eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/04/2024 19:39:45 - INFO - __main__ -   Test file: data/valid.java-cs.txt.java,data/valid.java-cs.txt.cs\n",
      "100%|██████████| 500/500 [00:00<00:00, 741.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# test loader\n",
    "files=[]\n",
    "if args.dev_filename is not None:\n",
    "    files.append(args.dev_filename)\n",
    "if args.test_filename is not None:\n",
    "    files.append(args.test_filename)\n",
    "    \n",
    "for idx,file in enumerate(files):   \n",
    "    logger.info(\"Test file: {}\".format(file))\n",
    "    eval_examples = read_examples(file)\n",
    "    # eval_examples = eval_examples[:50]\n",
    "    eval_features = convert_examples_to_features(eval_examples, tokenizer, args,stage='test')\n",
    "    eval_data = TextDataset(eval_features,args) \n",
    "\n",
    "    # Calculate bleu\n",
    "    eval_sampler = SequentialSampler(eval_data)\n",
    "    test_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=512, num_workers=54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source (Java): public InsertInstanceRequest() {super(\"Ots\", \"2016-06-20\", \"InsertInstance\", \"ots\");setMethod(MethodType.POST);}\n",
      "Target (C#): public InsertInstanceRequest(): base(\"Ots\", \"2016-06-20\", \"InsertInstance\", \"ots\", \"openAPI\"){Method = MethodType.POST;}\n"
     ]
    }
   ],
   "source": [
    "# Print examples of a code snippet\n",
    "example = eval_examples[2]\n",
    "print(f\"Source (Java): {example.source}\")\n",
    "print(f\"Target (C#): {example.target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load our pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Setup the model\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n",
    "config = config_class.from_pretrained(args.config_name)\n",
    "tokenizer = tokenizer_class.from_pretrained(args.tokenizer_name )\n",
    "\n",
    "#budild model\n",
    "encoder = model_class.from_pretrained(args.model_name_or_path,config=config)    \n",
    "decoder_layer = nn.TransformerDecoderLayer(d_model=config.hidden_size, nhead=config.num_attention_heads)\n",
    "decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n",
    "model=Seq2Seq(encoder=encoder,decoder=decoder,config=config,\n",
    "                beam_size=args.beam_size,max_length=args.max_target_length,\n",
    "                sos_id=tokenizer.cls_token_id,eos_id=tokenizer.sep_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved to saved_models/downloaded/pytorch_model_cfg.bin\n"
     ]
    }
   ],
   "source": [
    "# Load model from huggingface\n",
    "import requests\n",
    "\n",
    "# URL of the file\n",
    "url = \"https://huggingface.co/judynguyen16/graphcodebert-code-translation-java-cs/resolve/main/pytorch_model_cfg.bin\"\n",
    "\n",
    "# Path to save the file\n",
    "save_path = \"saved_models/downloaded/pytorch_model_cfg.bin\"\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url, stream=True)\n",
    "if response.status_code == 200:\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "    print(f\"File downloaded and saved to {save_path}\")\n",
    "else:\n",
    "    print(f\"Failed to download file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Now we have the model, we can update the weights\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.to(device)\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the inference process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataloader):\n",
    "    model.eval() \n",
    "    model.to(device)\n",
    "    p=[]\n",
    "    batch = next(iter(dataloader))\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    source_ids,source_mask,position_idx,att_mask,target_ids,target_mask = batch         \n",
    "          \n",
    "    with torch.no_grad():\n",
    "        preds = model(source_ids,source_mask,position_idx,att_mask, None, None)  \n",
    "        for pred in preds:\n",
    "            t=pred[0].cpu().numpy()\n",
    "            t=list(t)\n",
    "            if 0 in t:\n",
    "                t=t[:t.index(0)]\n",
    "            text = tokenizer.decode(t,clean_up_tokenization_spaces=False)\n",
    "            p.append(text)\n",
    "    return p\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 54 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "p = get_predictions(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions[0]: public DVRecord(RecordInputStream in1){_option_flags = in1.ReadInt();_promptTitle = ReadUnicodeString(in1);_errorTitle = ReadUnicodeString(in1);_promptText = ReadUnicodeString(in1);_errorText = ReadUnicodeString(in1);int field_size_first_formula = in1.ReadUShort();_not_used_1 = in1.ReadShort();_formula1 = NPOI.SS.Formula.Read(field_size_first_formula, in1);int field_size_sec_formula = in1.ReadUShort();_not_used_2 = in1.ReadShort();_regions = new CellRangeAddressList(in1);}\n"
     ]
    }
   ],
   "source": [
    "# Print out the predictions\n",
    "print(f\"Predictions[0]: {p[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 81.78\n",
      "X-Match: 60.9375\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Calculate BLEU score\n",
    "all_preds=[]\n",
    "accs = []\n",
    "with open(os.path.join(args.output_dir,\"dev.output\"),'w') as f, open(os.path.join(args.output_dir,\"dev.gold\"),'w') as f1:\n",
    "    for ref, gold in zip(p, eval_examples):\n",
    "        all_preds.append(ref)\n",
    "        f.write(ref+'\\n')\n",
    "        f1.write(gold.target+'\\n')     \n",
    "        accs.append(ref==gold.target)\n",
    "        \n",
    "# dev_bleu, xmatch = calculate_bleu(model, eval_examples, eval_dataloader)\n",
    "dev_bleu=round(_bleu(os.path.join(args.output_dir, \"dev.gold\"), os.path.join(args.output_dir, \"dev.output\")),2)\n",
    "xmatch=round(np.mean(accs)*100,4)\n",
    "\n",
    "print(f\"BLEU: {dev_bleu}\")  \n",
    "print(f\"X-Match: {xmatch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's it! We have successfully loaded the model and calculated the BLEU score.\n"
     ]
    }
   ],
   "source": [
    "print(\"That's it! We have successfully loaded the model and calculated the BLEU score.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the LightningModule model for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reload model from ./saved_models/java-cs/checkpoint-best-bleu/pytorch_model_Best BLEU+xMatch_141.39000000000001.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 54 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|██████████| 1/1 [06:26<00:00, 386.55s/it]\n"
     ]
    }
   ],
   "source": [
    "pretrained_model_path = \"./saved_models/java-cs/checkpoint-best-bleu/pytorch_model_Best BLEU+xMatch_141.39000000000001.bin\"\n",
    "print(\"reload model from {}\".format(pretrained_model_path))\n",
    "model.load_state_dict(torch.load(pretrained_model_path), strict=False)\n",
    "model.to(device)\n",
    "model.eval() \n",
    "np.bool = np.bool_\n",
    "p=[]\n",
    "for batch in tqdm(test_dataloader,total=len(test_dataloader)):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    source_ids,source_mask,position_idx,att_mask,target_ids,target_mask = batch                    \n",
    "    with torch.no_grad():\n",
    "        preds = model(source_ids,source_mask,position_idx,att_mask, None, None)  \n",
    "        for pred in preds:\n",
    "            t=pred[0].cpu().numpy()\n",
    "            t=list(t)\n",
    "            if 0 in t:\n",
    "                t=t[:t.index(0)]\n",
    "            text = tokenizer.decode(t,clean_up_tokenization_spaces=False)\n",
    "            p.append(text)\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m accs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(args\u001b[38;5;241m.\u001b[39moutput_dir,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdev.output\u001b[39m\u001b[38;5;124m\"\u001b[39m),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f, \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(args\u001b[38;5;241m.\u001b[39moutput_dir,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdev.gold\u001b[39m\u001b[38;5;124m\"\u001b[39m),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f1:\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ref, gold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43mp\u001b[49m, eval_examples):\n\u001b[1;32m      5\u001b[0m         predictions\u001b[38;5;241m.\u001b[39mappend(ref)\n\u001b[1;32m      6\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(ref\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "predictions=[]\n",
    "accs = []\n",
    "with open(os.path.join(args.output_dir,\"dev.output\"),'w') as f, open(os.path.join(args.output_dir,\"dev.gold\"),'w') as f1:\n",
    "    for ref, gold in zip(p, eval_examples):\n",
    "        predictions.append(ref)\n",
    "        f.write(ref+'\\n')\n",
    "        f1.write(gold.target+'\\n')     \n",
    "        accs.append(ref==gold.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_bleu=round(_bleu(os.path.join(args.output_dir, \"dev.gold\"), os.path.join(args.output_dir, \"dev.output\")),2)\n",
    "xmatch=round(np.mean(accs)*100,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 78.74, X-Match: 62.6\n"
     ]
    }
   ],
   "source": [
    "print(f\"BLEU: {dev_bleu}, X-Match: {xmatch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # try again the baseline model\n",
    "path = \"pytorch_model.bin\"\n",
    "model.load_state_dict(torch.load(path), strict=False)\n",
    "model.to(device)\n",
    "second_preds = get_predictions(model, test_dataloader)\n",
    "# predictions=[]\n",
    "# accs = []\n",
    "with open(os.path.join(args.output_dir,\"dev_baseline.output\"),'w') as f, open(os.path.join(args.output_dir,\"dev.gold\"),'w') as f1:\n",
    "    for ref, gold in zip(second_preds, eval_examples):\n",
    "        predictions.append(ref)\n",
    "        f.write(ref+'\\n')\n",
    "        f1.write(gold.target+'\\n')     \n",
    "        accs.append(ref==gold.target)\n",
    "        \n",
    "dev_bleu=round(_bleu(os.path.join(args.output_dir, \"dev.gold\"), os.path.join(args.output_dir, \"dev_baseline.output\")),2)\n",
    "xmatch=round(np.mean(accs)*100,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 74.2, X-Match: 60.9\n"
     ]
    }
   ],
   "source": [
    "print(f\"BLEU: {dev_bleu}, X-Match: {xmatch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ackaging (/opt/dlami/nvme/storage/conda/envs/pytorch/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: nltk in /opt/dlami/nvme/storage/conda/envs/pytorch/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /opt/dlami/nvme/storage/conda/envs/pytorch/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/dlami/nvme/storage/conda/envs/pytorch/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/dlami/nvme/storage/conda/envs/pytorch/lib/python3.10/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /opt/dlami/nvme/storage/conda/envs/pytorch/lib/python3.10/site-packages (from nltk) (4.66.4)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ackaging (/opt/dlami/nvme/storage/conda/envs/pytorch/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "better_samples = []\n",
    "\n",
    "for i, (first, second, gold) in enumerate(zip(p, second_preds, eval_examples)):\n",
    "    # Calculate BLEU scores for both models\n",
    "    bleu_first = sentence_bleu([gold.target.split()], first.split())\n",
    "    bleu_second = sentence_bleu([gold.target.split()], second.split())\n",
    "    \n",
    "    # Use BLEU to find better samples\n",
    "    if bleu_first > bleu_second:\n",
    "        better_samples.append(i)\n",
    "\n",
    "# Alternatively, using X-Match\n",
    "better_samples_xmatch = [i for i, (first, second, gold) in enumerate(zip(p, second_preds, eval_examples)) \n",
    "                         if first != second and first == gold.target]\n",
    "\n",
    "# better_samples now contains indices where the first model performs better using BLEU\n",
    "# better_samples_xmatch contains indices where the first model performs better using X-Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(better_samples_xmatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1\n",
      "ours: public override string ToString(){return Pattern();}\n",
      "bl: public override string ToString(){return pattern();}\n",
      "Gold: public override string ToString(){return Pattern();}\n",
      "Source: public String toString() {return pattern();}\n",
      "\n",
      "Example 3\n",
      "ours: public virtual bool contains(object o){return indexOf(o) != -1;}\n",
      "bl: public override bool contains(object o){return indexOf(o) != -1;}\n",
      "Gold: public virtual bool contains(object o){return indexOf(o) != -1;}\n",
      "Source: public boolean contains(Object o) {return indexOf(o) != -1;}\n",
      "\n",
      "Example 11\n",
      "ours: public CellRangeAddress GetCellRangeAddress(int index){return (CellRangeAddress)_list[index];}\n",
      "bl: public CellRangeAddress GetCellRangeAddress(int index){return _list[index];}\n",
      "Gold: public CellRangeAddress GetCellRangeAddress(int index){return (CellRangeAddress)_list[index];}\n",
      "Source: public CellRangeAddress getCellRangeAddress(int index) {return _list.get(index);}\n",
      "\n",
      "Example 19\n",
      "ours: public override ObjectId GetResultTreeId(){return (resultTree == null) ? null : resultTree.ToObjectId();}\n",
      "bl: public virtual ObjectId GetResultTreeId(){return (resultTree == null) ? null : resultTree.ToObjectId();}\n",
      "Gold: public override ObjectId GetResultTreeId(){return (resultTree == null) ? null : resultTree.ToObjectId();}\n",
      "Source: public ObjectId getResultTreeId() {return (resultTree == null) ? null : resultTree.toObjectId();}\n",
      "\n",
      "Example 20\n",
      "ours: public override bool Equals(Object o){bool rval = this == o;if (!rval && (o != null) && (o.GetType() == this.GetType())){IntList other = (IntList)o;if (other._limit == _limit){rval = true;for (int j = 0; rval && (j < _limit); j++){rval = _array[j] == other._array[j];}}}return rval;}\n",
      "bl: public override bool Equals(Object o){bool rval = this == o;if (!rval && ((o != null) && (o.GetType() == this.GetType())){rval = (IntList)o;if (other._limit == _limit){rval = true;for (int j = 0; rval && (j < _limit); j++){rval = _array[j] == other._array[j];}}}return rval;}\n",
      "Gold: public override bool Equals(Object o){bool rval = this == o;if (!rval && (o != null) && (o.GetType() == this.GetType())){IntList other = (IntList)o;if (other._limit == _limit){rval = true;for (int j = 0; rval && (j < _limit); j++){rval = _array[j] == other._array[j];}}}return rval;}\n",
      "Source: public boolean equals(final Object o){boolean rval = this == o;if (!rval && (o != null) && (o.getClass() == this.getClass())){IntList other = ( IntList ) o;if (other._limit == _limit){rval = true;for (int j = 0; rval && (j < _limit); j++){rval = _array[ j ] == other._array[ j ];}}}return rval;}\n",
      "\n",
      "Example 27\n",
      "ours: public virtual QueryPhraseMap SearchPhrase(string fieldName, IList<TermInfo> phraseCandidate){QueryPhraseMap root = GetRootMap(fieldName);if (root == null) return null;return root.SearchPhrase(phraseCandidate);}\n",
      "bl: public virtual QueryPhraseMap SearchPhrase(string fieldName, IList<TermInfo> phraseCandidate){QueryPhraseMap root = GetRootMap(fieldName);if (root == null){return null;}return root.SearchPhrase(phraseCandidate);}\n",
      "Gold: public virtual QueryPhraseMap SearchPhrase(string fieldName, IList<TermInfo> phraseCandidate){QueryPhraseMap root = GetRootMap(fieldName);if (root == null) return null;return root.SearchPhrase(phraseCandidate);}\n",
      "Source: public QueryPhraseMap searchPhrase( String fieldName, final List<TermInfo> phraseCandidate ){QueryPhraseMap root = getRootMap( fieldName );if( root == null ) return null;return root.searchPhrase( phraseCandidate );}\n",
      "\n",
      "Example 61\n",
      "ours: public virtual E push(E @object){addElement(@object);return @object;}\n",
      "bl: public virtual E push(E @object){addelement(@object);return @object;}\n",
      "Gold: public virtual E push(E @object){addElement(@object);return @object;}\n",
      "Source: public E push(E object) {addElement(object);return object;}\n",
      "\n",
      "Example 70\n",
      "ours: public virtual TestFailoverResponse TestFailover(TestFailoverRequest request){var options = new InvokeOptions();options.RequestMarshaller = TestFailoverRequestMarshaller.Instance;options.ResponseUnmarshaller = TestFailoverResponseUnmarshaller.Instance;return Invoke<TestFailoverResponse>(request, options);}\n",
      "bl: public virtual TestFailoverResponse TestFailover(TestFailoverRequest request){var options = new InvokeOptions();options.RequestMarshaller = TestFailoverRequestMarshaller.Instance;options.ResponseUnmarshaller = TestFailoverResponseUnmarshaller.Instance;return Invoke<TestOveroverResponse>(request, options);}\n",
      "Gold: public virtual TestFailoverResponse TestFailover(TestFailoverRequest request){var options = new InvokeOptions();options.RequestMarshaller = TestFailoverRequestMarshaller.Instance;options.ResponseUnmarshaller = TestFailoverResponseUnmarshaller.Instance;return Invoke<TestFailoverResponse>(request, options);}\n",
      "Source: public ReplicationGroup testFailover(TestFailoverRequest request) {request = beforeClientExecution(request);return executeTestFailover(request);}\n",
      "\n",
      "Example 81\n",
      "ours: public override bool remove(object o){if (!(o is java.util.MapClass.Entry<K, V>)){return false;}java.util.MapClass.Entry<object, object> e = (java.util.MapClass.Entry<object, object>)o;return this._enclosing.removeMapping(e.getKey(), e.getValue());}\n",
      "bl: public override bool remove(object o){if (!(o is java.util.MapClass.Entry<K, V>)){return false;}java.util.MapClass.Entry<object, object> e = (java.util.MapClass.Entry<object, object>)o;return this._enclosing.removeMapping(0);}\n",
      "Gold: public override bool remove(object o){if (!(o is java.util.MapClass.Entry<K, V>)){return false;}java.util.MapClass.Entry<object, object> e = (java.util.MapClass.Entry<object, object>)o;return this._enclosing.removeMapping(e.getKey(), e.getValue());}\n",
      "Source: @Override public boolean remove(Object o) {if (contains(o)) {Entry<?> entry = (Entry<?>) o;AtomicInteger frequency = backingMap.remove(entry.getElement());int numberRemoved = frequency.getAndSet(0);size -= numberRemoved;return true;}return false;}\n",
      "\n",
      "Example 88\n",
      "ours: public virtual DescribeStackDriftDetectionStatusResponse DescribeStackDriftDetectionStatus(DescribeStackDriftDetectionStatusRequest request){var options = new InvokeOptions();options.RequestMarshaller = DescribeStackDriftDetectionStatusRequestMarshaller.Instance;options.ResponseUnmarshaller = DescribeStackDriftDetectionStatusResponseUnmarshaller.Instance;return Invoke<DescribeStackDriftDetectionStatusResponse>(request, options);}\n",
      "bl: public virtual DescribeStackDriftDetectionStatusResponse DescribeStackDriftDetectionStatus(DescribeStackDriftDetectionStatusRequest request){var options = new InvokeOptions();options.RequestMarshaller = DescribeStackDriftDetectionStatusRequestMarshaller.Instance;options.ResponseUnmarshaller = DescribeStackDriftStatusResponseUnmarshaller.Instance;return Invoke<DescribeStackDriftDetectionStatusResponse>(request, options);}\n",
      "Gold: public virtual DescribeStackDriftDetectionStatusResponse DescribeStackDriftDetectionStatus(DescribeStackDriftDetectionStatusRequest request){var options = new InvokeOptions();options.RequestMarshaller = DescribeStackDriftDetectionStatusRequestMarshaller.Instance;options.ResponseUnmarshaller = DescribeStackDriftDetectionStatusResponseUnmarshaller.Instance;return Invoke<DescribeStackDriftDetectionStatusResponse>(request, options);}\n",
      "Source: public DescribeStackDriftDetectionStatusResult describeStackDriftDetectionStatus(DescribeStackDriftDetectionStatusRequest request) {request = beforeClientExecution(request);return executeDescribeStackDriftDetectionStatus(request);}\n",
      "\n",
      "Example 103\n",
      "ours: public override java.nio.ByteBuffer put(byte b){throw new java.nio.ReadOnlyBufferException();}\n",
      "bl: public override java.nio.ByteBuffer put(byte b){throw new System.NotImplementedException();}\n",
      "Gold: public override java.nio.ByteBuffer put(byte b){throw new java.nio.ReadOnlyBufferException();}\n",
      "Source: public ByteBuffer put(byte b) {throw new ReadOnlyBufferException();}\n",
      "\n",
      "Example 119\n",
      "ours: public override string ToString(string field){StringBuilder buffer = new StringBuilder();buffer.Append(\"spanFirst(\");buffer.Append(m_match.ToString(field));buffer.Append(\", \");buffer.Append(m_end);buffer.Append(\")\");buffer.Append(ToStringUtils.Boost(Boost));return buffer.ToString();}\n",
      "bl: public override string ToString(string field){StringBuilder buffer = new StringBuilder();buffer.Append(\"spanFirst(\");buffer.Append(m_match.ToString(field));buffer.Append(\", \");buffer.Append(m_end);buffer.Append(\")\");return buffer.ToString();}\n",
      "Gold: public override string ToString(string field){StringBuilder buffer = new StringBuilder();buffer.Append(\"spanFirst(\");buffer.Append(m_match.ToString(field));buffer.Append(\", \");buffer.Append(m_end);buffer.Append(\")\");buffer.Append(ToStringUtils.Boost(Boost));return buffer.ToString();}\n",
      "Source: public String toString(String field) {StringBuilder buffer = new StringBuilder();buffer.append(\"spanFirst(\");buffer.append(match.toString(field));buffer.append(\", \");buffer.append(end);buffer.append(\")\");return buffer.toString();}\n",
      "\n",
      "Example 127\n",
      "ours: public override int FillFields(byte[] data, int offset, IEscherRecordFactory recordFactory){int bytesRemaining = ReadHeader(data, offset);int pos = offset + 8;int size = 0;field_1_shapeId = LittleEndian.GetInt(data, pos + size); size += 4;field_2_flags = LittleEndian.GetInt(data, pos + size); size += 4;return RecordSize;}\n",
      "bl: public override int FillFields(byte[] data, int offset,IEscherRecordFactory recordFactory){int bytesRemaining = ReadHeader(data, offset);int pos = offset + 8;int size = 0;field_1_shapeId = LittleEndian.GetInt(data, pos + size); size += 4;field_2_flags = LittleEndian.GetInt(data, pos + size); size += 4;return RecordSize;}\n",
      "Gold: public override int FillFields(byte[] data, int offset, IEscherRecordFactory recordFactory){int bytesRemaining = ReadHeader(data, offset);int pos = offset + 8;int size = 0;field_1_shapeId = LittleEndian.GetInt(data, pos + size); size += 4;field_2_flags = LittleEndian.GetInt(data, pos + size); size += 4;return RecordSize;}\n",
      "Source: public int fillFields(byte[] data, int offset, EscherRecordFactory recordFactory) { readHeader( data, offset );int pos            = offset + 8;int size           = 0;field_1_shapeId    =  LittleEndian.getInt( data, pos + size );     size += 4;field_2_flags      =  LittleEndian.getInt( data, pos + size );     size += 4;return getRecordSize();}\n",
      "\n",
      "Example 150\n",
      "ours: public virtual void SetPackedGitMMAP(bool usemmap){packedGitMMAP = usemmap;}\n",
      "bl: public virtual void SetPackedGitMMAP(bool usemmap){packedGitMMAP = useMMAP;}\n",
      "Gold: public virtual void SetPackedGitMMAP(bool usemmap){packedGitMMAP = usemmap;}\n",
      "Source: public void setPackedGitMMAP(boolean usemmap) {packedGitMMAP = usemmap;}\n",
      "\n",
      "Example 154\n",
      "ours: public void Serialize(ILittleEndianOutput out1){out1.WriteShort(_extBookIndex);out1.WriteShort(_firstSheetIndex);out1.WriteShort(_lastSheetIndex);}\n",
      "bl: public override void Serialize(ILittleEndianOutput out1){out1.WriteShort(_extBookIndex);out1.WriteShort(_firstSheetIndex);out1.WriteShort(_lastSheetIndex);}\n",
      "Gold: public void Serialize(ILittleEndianOutput out1){out1.WriteShort(_extBookIndex);out1.WriteShort(_firstSheetIndex);out1.WriteShort(_lastSheetIndex);}\n",
      "Source: public void serialize(LittleEndianOutput out) {out.writeShort(_extBookIndex);out.writeShort(_firstSheetIndex);out.writeShort(_lastSheetIndex);}\n",
      "\n",
      "Example 156\n",
      "ours: public string[] GetValues(string name){var result = new List<string>();foreach (IIndexableField field in fields){if (field.Name.Equals(name, StringComparison.Ordinal) && field.GetStringValue() != null){result.Add(field.GetStringValue());}}if (result.Count == 0){return NO_STRINGS;}return result.ToArray();}\n",
      "bl: public string[] GetValues(string name){List<string> result = new List<string>();foreach (IIndexableField field in fields){if (field.Name.Equals(name, StringComparison.Ordinal) && field.GetStringValue() != null){result.Add(field.GetStringValue());}}if (result.Count == 0){return NO_STRINGS;}return result.ToArray();}\n",
      "Gold: public string[] GetValues(string name){var result = new List<string>();foreach (IIndexableField field in fields){if (field.Name.Equals(name, StringComparison.Ordinal) && field.GetStringValue() != null){result.Add(field.GetStringValue());}}if (result.Count == 0){return NO_STRINGS;}return result.ToArray();}\n",
      "Source: public final String[] getValues(String name) {List<String> result = new ArrayList<>();for (IndexableField field : fields) {if (field.name().equals(name) && field.stringValue() != null) {result.add(field.stringValue());}}if (result.size() == 0) {return NO_STRINGS;}return result.toArray(new String[result.size()]);}\n",
      "\n",
      "Example 202\n",
      "ours: public override void Serialize(ILittleEndianOutput out1){futureHeader.Serialize(out1);out1.WriteShort(isf_sharedFeatureType);out1.WriteByte(reserved);out1.WriteInt((int)cbHdrData);out1.Write(rgbHdrData);}\n",
      "bl: public override void Serialize(ILittleEndianOutput out1){futureHeader.Serialize(out1);out1.WriteShort(isf_sharedFeatureType);out1.WriteByte(reserved);out1.WriteInt((int)cbHdrData);out1.Write(rHdrData);}\n",
      "Gold: public override void Serialize(ILittleEndianOutput out1){futureHeader.Serialize(out1);out1.WriteShort(isf_sharedFeatureType);out1.WriteByte(reserved);out1.WriteInt((int)cbHdrData);out1.Write(rgbHdrData);}\n",
      "Source: public void serialize(LittleEndianOutput out) {futureHeader.serialize(out);out.writeShort(isf_sharedFeatureType);out.writeByte(reserved);out.writeInt((int)cbHdrData);out.write(rgbHdrData);}\n",
      "\n",
      "Example 224\n",
      "ours: public java.lang.StringBuffer append(bool b){return append(b ? \"true\" : \"false\");}\n",
      "bl: public java.lang.StringBuffer append(bool b){append0(c);return this;}\n",
      "Gold: public java.lang.StringBuffer append(bool b){return append(b ? \"true\" : \"false\");}\n",
      "Source: public StringBuffer append(long l) {IntegralToString.appendLong(this, l);return this;}\n",
      "\n",
      "Example 236\n",
      "ours: public override void Serialize(ILittleEndianOutput out1){out1.WriteShort(field_1_option_flag);out1.WriteShort(field_2_ixals);out1.WriteShort(field_3_not_used);out1.WriteByte(field_4_name.Length);StringUtil.WriteUnicodeStringFlagAndData(out1, field_4_name);if (!IsOLELink && !IsStdDocumentNameIdentifier){if (IsAutomaticLink){if (_ddeValues != null){out1.WriteByte(_nColumns - 1);out1.WriteShort(_nRows - 1);ConstantValueParser.Encode(out1, _ddeValues);}}else{field_5_name_definition.Serialize(out1);}}}\n",
      "bl: public override void Serialize(ILittleEndianOutput out1){out1.WriteShort(field_1_option_flag);out1.WriteShort(field_2_ixals);out1.WriteShort(field_3_not_used);out1.WriteByte(field_4_name.Length);StringUtil.WriteUnicodeStringFlagAndData(out1, field_4_name);if (!IsOLELink && !IsOLELink && !IsStdDocumentNameIdentifier){if (IsAutomaticLink){out1.WriteByte(_nColumns - 1);out1.WriteByte(_nRows - 1);out1.WriteShort(_nRows - 1);ConstantValueParser.Encode(out1, _ddeValues);}}else{field_5_name_definition.Serialize(out1);}}}\n",
      "Gold: public override void Serialize(ILittleEndianOutput out1){out1.WriteShort(field_1_option_flag);out1.WriteShort(field_2_ixals);out1.WriteShort(field_3_not_used);out1.WriteByte(field_4_name.Length);StringUtil.WriteUnicodeStringFlagAndData(out1, field_4_name);if (!IsOLELink && !IsStdDocumentNameIdentifier){if (IsAutomaticLink){if (_ddeValues != null){out1.WriteByte(_nColumns - 1);out1.WriteShort(_nRows - 1);ConstantValueParser.Encode(out1, _ddeValues);}}else{field_5_name_definition.Serialize(out1);}}}\n",
      "Source: public void serialize(LittleEndianOutput out) {out.writeShort(field_1_option_flag);out.writeShort(field_2_ixals);out.writeShort(field_3_not_used);out.writeByte(field_4_name.length());StringUtil.writeUnicodeStringFlagAndData(out, field_4_name);if(!isOLELink() && !isStdDocumentNameIdentifier()){if(isAutomaticLink()){if(_ddeValues != null) {out.writeByte(_nColumns-1);out.writeShort(_nRows-1);ConstantValueParser.encode(out, _ddeValues);}} else {field_5_name_definition.serialize(out);}}}\n",
      "\n",
      "Example 262\n",
      "ours: public IgnoreNode(IList<IgnoreRule> rules){this.rules = rules;}\n",
      "bl: public IgnoreNode(ILoreRule<IgnoreRule> rules){this.rules = rules;}\n",
      "Gold: public IgnoreNode(IList<IgnoreRule> rules){this.rules = rules;}\n",
      "Source: public IgnoreNode(List<FastIgnoreRule> rules) {this.rules = rules;}\n",
      "\n",
      "Example 277\n",
      "ours: public override void Flush(){try{BeginWrite();dst.Flush();}catch (ThreadInterruptedException){throw WriteTimedOut();}finally{EndWrite();}}\n",
      "bl: public override void flush(){try{BeginWrite();dst.flush();}catch (ThreadInterruptedException){throw WriteTimedOut();}finally{EndWrite();}}\n",
      "Gold: public override void Flush(){try{BeginWrite();dst.Flush();}catch (ThreadInterruptedException){throw WriteTimedOut();}finally{EndWrite();}}\n",
      "Source: public void flush() throws IOException {try {beginWrite();dst.flush();} catch (InterruptedIOException e) {throw writeTimedOut(e);} finally {endWrite();}}\n",
      "\n",
      "Example 311\n",
      "ours: public virtual Hyphenation Hyphenate(string word, int remainCharCount, int pushCharCount){char[] w = word.ToCharArray();return Hyphenate(w, 0, w.Length, remainCharCount, pushCharCount);}\n",
      "bl: public virtual Hyphenation Hyphenate(string word, int remainCharCount, int pushCharCount){char[] w = word.ToCharArray();return Hyphenate(w, 0, w.Length, pushCharCount);}\n",
      "Gold: public virtual Hyphenation Hyphenate(string word, int remainCharCount, int pushCharCount){char[] w = word.ToCharArray();return Hyphenate(w, 0, w.Length, remainCharCount, pushCharCount);}\n",
      "Source: public Hyphenation hyphenate(String word, int remainCharCount,int pushCharCount) {char[] w = word.toCharArray();return hyphenate(w, 0, w.length, remainCharCount, pushCharCount);}\n",
      "\n",
      "Example 320\n",
      "ours: public ContinueRecord(RecordInputStream in1){field_1_data = in1.ReadRemainder();}\n",
      "bl: public ContinueRecord(RecordInputStream in1){_data = in1.ReadRemainder();}\n",
      "Gold: public ContinueRecord(RecordInputStream in1){field_1_data = in1.ReadRemainder();}\n",
      "Source: public ContinueRecord(RecordInputStream in) {_data = in.readRemainder();}\n",
      "\n",
      "Example 340\n",
      "ours: public override void Close(){if (sock != null){try{sch.ReleaseSession(sock);}finally{sock = null;}}}\n",
      "bl: public override void Close(){if (sock != null){try{sch.ReleaseSession(sock);}fock = null;}}}\n",
      "Gold: public override void Close(){if (sock != null){try{sch.ReleaseSession(sock);}finally{sock = null;}}}\n",
      "Source: public void close() {if (sock != null) {try {sch.releaseSession(sock);} finally {sock = null;}}}\n",
      "\n",
      "Example 352\n",
      "ours: public virtual ICollection<string> GetNames(string section, string subsection){return GetState().GetNames(section, subsection);}\n",
      "bl: public virtual ICollection<string> GetNames(string section, string subsection){return GetState().GetNames(section, subscription);}\n",
      "Gold: public virtual ICollection<string> GetNames(string section, string subsection){return GetState().GetNames(section, subsection);}\n",
      "Source: public Set<String> getNames(String section, String subsection) {return getState().getNames(section, subsection);}\n",
      "\n",
      "Example 367\n",
      "ours: public ValueEval Evaluate(ValueEval[] args, OperationEvaluationContext ec){throw new NotImplementedFunctionException(_functionName);}\n",
      "bl: public ValueEval Evaluate(ValueEval[] args, OperationEvaluationContext ec){throw new System.NotImplementedFunctionException(_functionName);}\n",
      "Gold: public ValueEval Evaluate(ValueEval[] args, OperationEvaluationContext ec){throw new NotImplementedFunctionException(_functionName);}\n",
      "Source: public ValueEval evaluate(ValueEval[] args, OperationEvaluationContext ec) {throw new NotImplementedFunctionException(_functionName);}\n",
      "\n",
      "Example 373\n",
      "ours: public java.nio.charset.CoderResult flush(java.nio.CharBuffer @out){if (status != END && status != INIT){throw new System.InvalidOperationException();}java.nio.charset.CoderResult result = implFlush(@out);if (result == java.nio.charset.CoderResult.UNDERFLOW){status = FLUSH;}return result;}\n",
      "bl: public java.nio.charset.CoderResult flush(java.nio.CharBuffer @out){if (status != END && status != INIT){throw new System.InvalidOperationException();}java.nio.charset.charset.CoderResult result = implFlush(@out);if (result == java.nio.charset.CoderResult.charset.CoderResult.UNDERFLOW){status = FLUSH;}return result;}\n",
      "Gold: public java.nio.charset.CoderResult flush(java.nio.CharBuffer @out){if (status != END && status != INIT){throw new System.InvalidOperationException();}java.nio.charset.CoderResult result = implFlush(@out);if (result == java.nio.charset.CoderResult.UNDERFLOW){status = FLUSH;}return result;}\n",
      "Source: public final CoderResult flush(CharBuffer out) {if (status != END && status != INIT) {throw new IllegalStateException();}CoderResult result = implFlush(out);if (result == CoderResult.UNDERFLOW) {status = FLUSH;}return result;}\n",
      "\n",
      "Example 386\n",
      "ours: public virtual TokenStream Init(TokenStream tokenStream){termAtt = tokenStream.AddAttribute<ICharTermAttribute>();return null;}\n",
      "bl: public override TokenStream Init(TokenStream tokenStream){termAtt = tokenStream.AddAttribute<ICharTermAttribute>();return null;}\n",
      "Gold: public virtual TokenStream Init(TokenStream tokenStream){termAtt = tokenStream.AddAttribute<ICharTermAttribute>();return null;}\n",
      "Source: public TokenStream init(TokenStream tokenStream) {termAtt = tokenStream.addAttribute(CharTermAttribute.class);return null;}\n",
      "\n",
      "Example 392\n",
      "ours: public virtual int GetNumberOfOnChannelTokens(){int n = 0;Fill();for (int i = 0; i < tokens.Count; i++){IToken t = tokens[i];if (t.Channel == channel){n++;}if (t.Type == TokenConstants.EOF){break;}}return n;}\n",
      "bl: public virtual int GetNumberOfOnChannelTokens(){int n = 0;Fill();for (int i = 0; i < tokens.Count; i++){IToken t = tokens[i];if (t.Channel == TokenConstants.EOF){n++;}if (t.Type == TokenConstants.EOF){break;}}return n;}\n",
      "Gold: public virtual int GetNumberOfOnChannelTokens(){int n = 0;Fill();for (int i = 0; i < tokens.Count; i++){IToken t = tokens[i];if (t.Channel == channel){n++;}if (t.Type == TokenConstants.EOF){break;}}return n;}\n",
      "Source: public int getNumberOfOnChannelTokens() {int n = 0;fill();for (int i = 0; i < tokens.size(); i++) {Token t = tokens.get(i);if ( t.getChannel()==channel ) n++;if ( t.getType()==Token.EOF ) break;}return n;}\n",
      "\n",
      "Example 435\n",
      "ours: public override byte[] GetCachedBytes(){return data;}\n",
      "bl: public virtual byte[] GetCachedBytes(){return data;}\n",
      "Gold: public override byte[] GetCachedBytes(){return data;}\n",
      "Source: public byte[] getCachedBytes() {return data;}\n",
      "\n",
      "Example 442\n",
      "ours: public virtual string getEncoding(){if (encoder == null){return null;}return java.io.HistoricalCharsetNames.get(encoder.charset());}\n",
      "bl: public virtual string getEncoding(){if (encoder == null){return null;}return java.util.HistoricalCharsetNames.get(encoder.charset());}\n",
      "Gold: public virtual string getEncoding(){if (encoder == null){return null;}return java.io.HistoricalCharsetNames.get(encoder.charset());}\n",
      "Source: public String getEncoding() {if (encoder == null) {return null;}return HistoricalCharsetNames.get(encoder.charset());}\n",
      "\n",
      "Example 456\n",
      "ours: public override String ToString(){StringBuilder sb = new StringBuilder();sb.Append(\"[\").Append(\"USERSVIEWEND\").Append(\"] (0x\");sb.Append(StringUtil.ToHexString(sid).ToUpper() + \")\\n\");sb.Append(\"  rawData=\").Append(HexDump.ToHex(_rawData)).Append(\"\\n\");sb.Append(\"[/\").Append(\"USERSVIEWEND\").Append(\"]\\n\");return sb.ToString();}\n",
      "bl: public override String ToString(){StringBuilder sb = new StringBuilder();sb.Append(\"[').Append(\"USERSVIEWEND\").Append(\"] (0x\");sb.Append(StringUtil.ToHexString(sid).ToUpper() + \")\\n\");sb.Append(\"  rawData=\").Append(HexDump.ToHex(_rawData)).Append(\"\\n\");sb.Append(\"[/\").Append(\"USERSVIEWEND\").Append(\"]\\n\");return sb.ToString();}\n",
      "Gold: public override String ToString(){StringBuilder sb = new StringBuilder();sb.Append(\"[\").Append(\"USERSVIEWEND\").Append(\"] (0x\");sb.Append(StringUtil.ToHexString(sid).ToUpper() + \")\\n\");sb.Append(\"  rawData=\").Append(HexDump.ToHex(_rawData)).Append(\"\\n\");sb.Append(\"[/\").Append(\"USERSVIEWEND\").Append(\"]\\n\");return sb.ToString();}\n",
      "Source: public String toString() {StringBuilder sb = new StringBuilder();sb.append('[').append(\"USERSVIEWEND\").append(\"] (0x\");sb.append(Integer.toHexString(sid).toUpperCase(Locale.ROOT)).append(\")\\n\");sb.append(\"  rawData=\").append(HexDump.toHex(_rawData)).append(\"\\n\");sb.append(\"[/\").append(\"USERSVIEWEND\").append(\"]\\n\");return sb.toString();}\n",
      "\n",
      "Example 462\n",
      "ours: public virtual void remove(){if (this.lastEntryReturned == null){throw new System.InvalidOperationException();}if (this._enclosing.modCount != this.expectedModCount){throw new java.util.ConcurrentModificationException();}this._enclosing.remove(this.lastEntryReturned.key);this.lastEntryReturned = null;this.expectedModCount = this._enclosing.modCount;}\n",
      "bl: public virtual void remove(){if (this.lastReturned == null){throw new System.InvalidOperationException();}if (this._enclosing.remove(this.lastReturned.key);this.lastReturned = null;}\n",
      "Gold: public virtual void remove(){if (this.lastEntryReturned == null){throw new System.InvalidOperationException();}if (this._enclosing.modCount != this.expectedModCount){throw new java.util.ConcurrentModificationException();}this._enclosing.remove(this.lastEntryReturned.key);this.lastEntryReturned = null;this.expectedModCount = this._enclosing.modCount;}\n",
      "Source: public void remove() {if (lastReturned == null)throw new IllegalStateException();ConcurrentHashMap.this.remove(lastReturned.key);lastReturned = null;}\n",
      "\n",
      "Example 466\n",
      "ours: public override int lastIndexOf(object @object){if (@object != null){{for (int i = a.Length - 1; i >= 0; i--){if (@object.Equals(a[i])){return i;}}}}else{{for (int i = a.Length - 1; i >= 0; i--){if ((object)a[i] == null){return i;}}}}return -1;}\n",
      "bl: public virtual int lastIndexOf(object @object){if (@object != null){{for (int i = a.Length - 1; i >= 0; i--){if (@object.Equals(a[i])){return i;}}}else{{for (int i = a.Length - 1; i >= 0; i--){if ((object)a[i] == null){return i;}}}}return -1;}\n",
      "Gold: public override int lastIndexOf(object @object){if (@object != null){{for (int i = a.Length - 1; i >= 0; i--){if (@object.Equals(a[i])){return i;}}}}else{{for (int i = a.Length - 1; i >= 0; i--){if ((object)a[i] == null){return i;}}}}return -1;}\n",
      "Source: public int lastIndexOf(Object object) {if (object != null) {for (int i = a.length - 1; i >= 0; i--) {if (object.equals(a[i])) {return i;}}} else {for (int i = a.length - 1; i >= 0; i--) {if (a[i] == null) {return i;}}}return -1;}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print out the better samples\n",
    "for i in better_samples_xmatch:\n",
    "    print(f\"Example {i}\")\n",
    "    print(f\"ours: {p[i]}\")\n",
    "    print(f\"bl: {second_preds[i]}\")\n",
    "    print(f\"Gold: {eval_examples[i].target}\")\n",
    "    # print source\n",
    "    print(f\"Source: {eval_examples[i].source}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the better samples src and target to two files\n",
    "with open(\"custom_data/better_samples_src.txt.java\", \"w\") as f:\n",
    "    for i in better_samples_xmatch:\n",
    "        f.write(eval_examples[i].source + \"\\n\")\n",
    "with open(\"custom_data/better_samples_tgt.txt.cs\", \"w\") as f:\n",
    "    for i in better_samples_xmatch:\n",
    "        f.write(eval_examples[i].target + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the outputs to a file\n",
    "with open(\"custom_data/better_samples_output.txt.cs\", \"w\") as f:\n",
    "    for i in better_samples_xmatch:\n",
    "        f.write(p[i] + \"\\n\")\n",
    "with open(\"custom_data/better_samples_baseline_output.txt.cs\", \"w\") as f:\n",
    "    for i in better_samples_xmatch:\n",
    "        f.write(second_preds[i] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# login huggerface\n",
    "# !huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repo_id = \"judynguyen16/graphcodebert-code-translation-java-cs\"\n",
    "# !huggingface-cli repo create \"judynguyen16/graphcodebert-code-translation-java-cs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "12/04/2024 19:43:43 - WARNING - huggingface_hub.hf_api -   No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "# Push model and tokenizer to Hugging Face Hub\n",
    "from huggingface_hub import upload_file\n",
    "\n",
    "repo_id = \"judynguyen16/graphcodebert-code-translation-java-cs\"\n",
    "\n",
    "files_to_upload = {\n",
    "    # \"pytorch_model.bin\": \"/home/ubuntu/judy/transformer-code-translation/GraphCodeBERT/translation/saved_models/java-cs/checkpoint-best-ppl/pytorch_model.bin\",\n",
    "    # \"pytorch_model_cfg.bin\": \"/home/ubuntu/judy/transformer-code-translation/GraphCodeBERT/translation/saved_models/java-cs/checkpoint-best-bleu/pytorch_model_Best BLEU+xMatch_141.39000000000001.bin\"\n",
    "    \"pytorch_model_cfg.bin\": \"/home/ubuntu/judy/transformer-code-translation/translation/saved_models/java-cs/pytorch_model_Best_BLEU+xMatch.bin\"\n",
    "    \n",
    "}\n",
    "\n",
    "for dest_path, local_path in files_to_upload.items():\n",
    "    upload_file(\n",
    "        path_or_fileobj=local_path,\n",
    "        path_in_repo=dest_path,\n",
    "        repo_id=repo_id,\n",
    "        repo_type=\"model\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model from hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved to pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL of the file\n",
    "url = \"https://huggingface.co/judynguyen16/graphcodebert-code-translation-java-cs/resolve/main/pytorch_model_cfg.bin\"\n",
    "\n",
    "# Path to save the file\n",
    "save_path = \"translation/saved_models/downloaded/pytorch_model_cfg.bin\"\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url, stream=True)\n",
    "if response.status_code == 200:\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "    print(f\"File downloaded and saved to {save_path}\")\n",
    "else:\n",
    "    print(f\"Failed to download file. Status code: {response.status_code}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
